name: Unit Tests

on:
  pull_request:
    branches: [ "master" ]
  push:
    branches: [ "master" ]

# Minimum coverage threshold for enforcement
env:
  COVERAGE_THRESHOLD: 49

jobs:
  test:
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      checks: write
      pull-requests: write
      issues: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for version detection

    - name: Set reusable strings
      id: strings
      shell: bash
      run: |
        echo "build-output-dir=${{ github.workspace }}/build" >> "$GITHUB_OUTPUT"
    
    - name: Make scripts executable
      run: chmod -R +x ./scripts/

    - name: Install Dependencies
      run: |
        if [ "$RUNNER_OS" == "Linux" ]; then
          ./scripts/installUbuntuPreReqs.sh
        else
          echo "$RUNNER_OS not supported"
          exit 1
        fi
      shell: bash

    - name: Configure CMake
      run: |
        echo "âœ… Coverage instrumentation ENABLED (alloutput:BOOL=ON)"
        
        cmake -B ${{ steps.strings.outputs.build-output-dir }} \
          -DCMAKE_CXX_COMPILER=g++ \
          -DCMAKE_C_COMPILER=gcc \
          -DCMAKE_BUILD_TYPE=Debug \
          -DBUILD_TESTS=ON \
          -Dalloutput:BOOL=ON \
          -S ${{ github.workspace }}
        
        # Verify the option was set
        echo ""
        echo "=== Verifying CMake Configuration ==="
        grep "alloutput" ${{ steps.strings.outputs.build-output-dir }}/CMakeCache.txt || echo "alloutput not in cache!"

    - name: Build
      run: |
        echo "=== Building Debug Configuration with gcc ==="
        cmake --build ${{ steps.strings.outputs.build-output-dir }} --config Debug --verbose
        
    - name: Verify Build Flags
      working-directory: ${{ steps.strings.outputs.build-output-dir }}
      run: |
        echo "=== Checking Compiled Flags ==="
        echo "CMakeCache.txt alloutput setting:"
        grep -i "alloutput" CMakeCache.txt || echo "alloutput not found in cache"
        echo ""
        echo "CMakeCache.txt CXX flags:"
        grep "CMAKE_CXX_FLAGS:" CMakeCache.txt || echo "No CXX flags found"
        echo ""
        echo "Checking test executable for coverage support:"
        if [ -f "tests/ParticleViewerTests" ]; then
          echo "Test executable exists"
          nm tests/ParticleViewerTests | grep -i "gcov" | head -5 || echo "No gcov symbols found in executable"
        else
          echo "Test executable not found at tests/ParticleViewerTests"
          find . -name "ParticleViewerTests" -type f
        fi

    - name: Run Tests
      working-directory: ${{ steps.strings.outputs.build-output-dir }}
      run: ctest --build-config Debug --output-on-failure --verbose

    - name: Verify Coverage Data Files
      working-directory: ${{ steps.strings.outputs.build-output-dir }}
      run: |
        echo "=== Checking for coverage data files ==="
        echo "Looking for .gcda files (coverage data):"
        find . -name "*.gcda" -type f | head -20 || echo "âŒ No .gcda files found!"
        echo ""
        echo "Looking for .gcno files (coverage notes):"
        find . -name "*.gcno" -type f | head -20 || echo "âŒ No .gcno files found!"
        echo ""
        echo "Counting coverage files:"
        GCDA_COUNT=$(find . -name "*.gcda" -type f | wc -l)
        GCNO_COUNT=$(find . -name "*.gcno" -type f | wc -l)
        echo "Found ${GCDA_COUNT} .gcda files and ${GCNO_COUNT} .gcno files"
        
        if [ "$GCDA_COUNT" -eq 0 ]; then
          echo "âš ï¸  WARNING: No coverage data files found! Tests may not be instrumented."
        fi

    - name: Generate Coverage Report
      id: coverage
      working-directory: ${{ steps.strings.outputs.build-output-dir }}
      run: |
        # Install gcovr if not available
        sudo apt-get update
        sudo apt-get install -y gcovr
        
        echo "=== Generating coverage report ==="
        echo "Root directory: ${{ github.workspace }}"
        echo "Working directory: $(pwd)"
        echo ""
        
        # Generate coverage report with JSON for parsing (verbose mode)
        gcovr --root ${{ github.workspace }} \
              --filter '${{ github.workspace }}/src/' \
              --exclude '${{ github.workspace }}/src/glad/' \
              --exclude '${{ github.workspace }}/src/stb_*' \
              --exclude '${{ github.workspace }}/src/tinyFileDialogs/' \
              --print-summary \
              --json coverage.json \
              --txt coverage.txt \
              --html coverage.html \
              --verbose || echo "âš ï¸  gcovr completed with warnings"
        
        # Display coverage summary
        echo ""
        echo "=== Coverage Summary ==="
        cat coverage.txt || echo "âŒ No coverage.txt generated"
        echo ""
        
        # Verify coverage.json exists and show its content structure
        echo "=== Verifying coverage.json ==="
        if [ -f "coverage.json" ]; then
          echo "âœ“ coverage.json exists"
          echo "File size: $(stat -c%s coverage.json) bytes"
          echo "First 500 characters:"
          head -c 500 coverage.json
          echo ""
          echo "..."
        else
          echo "âŒ coverage.json NOT FOUND"
          echo "Files in current directory:"
          ls -lah
        fi
        echo ""
        
        # Extract coverage metrics using dedicated script
        # Script reads coverage.json and outputs: line_coverage branch_coverage
        echo "=== Running extract-coverage.py ==="
        COVERAGE_OUTPUT=$(python3 ${{ github.workspace }}/scripts/extract-coverage.py)
        echo "Raw script output: '$COVERAGE_OUTPUT'"
        LINE_COVERAGE=$(echo $COVERAGE_OUTPUT | awk '{print $1}')
        BRANCH_COVERAGE=$(echo $COVERAGE_OUTPUT | awk '{print $2}')
        
        echo "=== Extracted Metrics ==="
        echo "Line coverage: ${LINE_COVERAGE}%"
        echo "Branch coverage: ${BRANCH_COVERAGE}%"
        echo "line_coverage=${LINE_COVERAGE}" >> "$GITHUB_OUTPUT"
        echo "branch_coverage=${BRANCH_COVERAGE}" >> "$GITHUB_OUTPUT"

    - name: Enforce Coverage Threshold
      run: |
        LINE_COVERAGE=${{ steps.coverage.outputs.line_coverage }}
        THRESHOLD=${{ env.COVERAGE_THRESHOLD }}
        
        echo "Line coverage: ${LINE_COVERAGE}%"
        echo "Threshold: ${THRESHOLD}%"
        
        # Compare as integers to avoid floating point issues
        # Handle case where LINE_COVERAGE might not have a decimal point
        if [[ "${LINE_COVERAGE}" == *"."* ]]; then
          LINE_INT="${LINE_COVERAGE%%.*}"
        else
          LINE_INT="${LINE_COVERAGE}"
        fi
        
        # Ensure LINE_INT is numeric, default to 0 if empty or non-numeric
        if ! [[ "${LINE_INT}" =~ ^[0-9]+$ ]]; then
          echo "Warning: Could not parse coverage value '${LINE_COVERAGE}', defaulting to 0"
          LINE_INT=0
        fi
        
        if [ "${LINE_INT}" -lt "${THRESHOLD}" ]; then
          echo "âŒ Coverage ${LINE_COVERAGE}% is below threshold ${THRESHOLD}%"
          exit 1
        else
          echo "âœ… Coverage ${LINE_COVERAGE}% meets threshold ${THRESHOLD}%"
        fi

    - name: Comment Coverage on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const lineCoverage = '${{ steps.coverage.outputs.line_coverage }}';
          const branchCoverage = '${{ steps.coverage.outputs.branch_coverage }}';
          const threshold = '${{ env.COVERAGE_THRESHOLD }}';
          
          const coverageInt = parseInt(lineCoverage);
          const thresholdInt = parseInt(threshold);
          const status = coverageInt >= thresholdInt ? 'âœ…' : 'âŒ';
          
          const body = `## ðŸ“Š Code Coverage Report
          
          | Metric | Value | Status |
          |--------|-------|--------|
          | Line Coverage | ${lineCoverage}% | ${status} |
          | Branch Coverage | ${branchCoverage}% | - |
          | Threshold | ${threshold}% | - |
          
          ${coverageInt >= thresholdInt ? 'âœ… Coverage meets threshold!' : 'âŒ Coverage is below threshold!'}
          
          > Third-party code excluded: glad, stb_*, tinyFileDialogs
          `;
          
          // Find existing comment
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });
          
          const botComment = comments.find(comment => 
            comment.user.type === 'Bot' && 
            comment.body.includes('Code Coverage Report')
          );
          
          if (botComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: body
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
          }

    - name: Upload Coverage Report
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report
        path: |
          ${{ steps.strings.outputs.build-output-dir }}/coverage.txt
          ${{ steps.strings.outputs.build-output-dir }}/coverage.html
          ${{ steps.strings.outputs.build-output-dir }}/coverage.json

    - name: Check Test Results
      if: always()
      run: |
        if [ -f "${{ steps.strings.outputs.build-output-dir }}/Testing/Temporary/LastTest.log" ]; then
          echo "Test log:"
          cat "${{ steps.strings.outputs.build-output-dir }}/Testing/Temporary/LastTest.log"
        fi

  visual-regression:
    runs-on: ubuntu-latest
    needs: test

    permissions:
      contents: write
      checks: write
      pull-requests: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: ${{ github.head_ref }}

    - name: Set reusable strings
      id: strings
      shell: bash
      run: |
        echo "build-output-dir=${{ github.workspace }}/build" >> "$GITHUB_OUTPUT"

    - name: Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          build-essential cmake \
          libglfw3-dev libglm-dev \
          mesa-utils xvfb \
          libgl1-mesa-dev libglu1-mesa-dev

    - name: Configure CMake
      run: |
        cmake -B ${{ steps.strings.outputs.build-output-dir }} \
          -DCMAKE_CXX_COMPILER=g++ \
          -DCMAKE_C_COMPILER=gcc \
          -DCMAKE_BUILD_TYPE=Release \
          -DBUILD_TESTS=ON \
          -S ${{ github.workspace }}

    - name: Build Tests
      run: |
        cmake --build ${{ steps.strings.outputs.build-output-dir }} \
          --config Release \
          --target ParticleViewerTests

    - name: Run Visual Regression Tests
      id: visual-tests
      working-directory: ${{ steps.strings.outputs.build-output-dir }}/tests
      run: |
        # Run only visual regression fixture tests under Xvfb
        xvfb-run -a ./ParticleViewerTests \
          --gtest_filter="VisualRegressionTest.*" \
          --gtest_output=xml:visual-test-results.xml \
          2>&1 | tee visual-test-output.txt

        # Capture exit code
        TEST_EXIT_CODE=${PIPESTATUS[0]}
        echo "test_exit_code=${TEST_EXIT_CODE}" >> "$GITHUB_OUTPUT"

        # Parse test results using gtest final summary lines
        TOTAL=$(grep -E '^\[==========\] [0-9]+ tests? from [0-9]+ test suites? ran\.' visual-test-output.txt \
          | tail -1 \
          | grep -oE '[0-9]+' \
          | head -1 || echo "0")
        PASSED=$(grep -E '^\[  PASSED  \] [0-9]+ tests?\.' visual-test-output.txt \
          | tail -1 \
          | grep -oE '[0-9]+' \
          | head -1 || echo "0")
        FAILED=$(grep -E '^\[  FAILED  \] [0-9]+ tests?, listed below:' visual-test-output.txt \
          | tail -1 \
          | grep -oE '[0-9]+' \
          | head -1 || echo "0")

        echo "total_tests=${TOTAL}" >> "$GITHUB_OUTPUT"
        echo "passed_tests=${PASSED}" >> "$GITHUB_OUTPUT"
        echo "failed_tests=${FAILED}" >> "$GITHUB_OUTPUT"

        exit ${TEST_EXIT_CODE}

    - name: Commit Visual Test Images to Branch
      if: always()
      run: |
        git config user.name "github-actions[bot]"
        git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

        # Create output directory in repo
        mkdir -p tests/visual-regression/output

        # Copy generated images
        cp -f ${{ steps.strings.outputs.build-output-dir }}/tests/artifacts/*.png tests/visual-regression/output/ 2>/dev/null || true
        cp -f ${{ steps.strings.outputs.build-output-dir }}/tests/diffs/*.png tests/visual-regression/output/ 2>/dev/null || true

        # List what we found
        echo "=== Visual test output images ==="
        ls -la tests/visual-regression/output/ 2>/dev/null || echo "No images found"

        # Commit and push (skip CI to avoid infinite loop)
        git add tests/visual-regression/output/
        if git diff --staged --quiet; then
          echo "No image changes to commit"
        else
          git commit -m "chore: update visual regression test images [skip ci]"
          git push
        fi

    - name: Upload Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: visual-regression-results
        path: |
          ${{ steps.strings.outputs.build-output-dir }}/tests/visual-test-results.xml
          ${{ steps.strings.outputs.build-output-dir }}/tests/visual-test-output.txt
        retention-days: 7

    - name: Comment Visual Diff on PR
      if: always() && github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          const testExitCode = '${{ steps.visual-tests.outputs.test_exit_code }}';
          const total = '${{ steps.visual-tests.outputs.total_tests }}' || '0';
          const passed = '${{ steps.visual-tests.outputs.passed_tests }}' || '0';
          const failed = '${{ steps.visual-tests.outputs.failed_tests }}' || '0';
          const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
          const branch = context.payload.pull_request.head.ref;
          const rawBase = `https://raw.githubusercontent.com/${context.repo.owner}/${context.repo.repo}/${branch}/tests/visual-regression/output`;

          const status = testExitCode === '0' ? 'âœ…' : 'âŒ';
          const statusText = testExitCode === '0' ? 'All visual tests passed!' : 'Visual regression detected!';

          let body = `## ðŸŽ¨ Visual Regression Test Report\n\n`;
          body += `**Status:** ${status} ${statusText}\n\n`;
          body += `| Metric | Value |\n`;
          body += `|--------|-------|\n`;
          body += `| Total Tests | ${total} |\n`;
          body += `| Passed | ${passed} |\n`;
          body += `| Failed | ${failed} |\n\n`;

          // List image files from the output directory
          const outputDir = 'tests/visual-regression/output';
          const imageFiles = [];
          if (fs.existsSync(outputDir)) {
            const files = fs.readdirSync(outputDir).filter(f => f.endsWith('.png'));
            for (const file of files) {
              imageFiles.push(file);
            }
          }

          if (imageFiles.length > 0) {
            body += `### ðŸ“¸ Visual Test Images\n\n`;

            // Group by test name (strip _baseline/_current/_diff suffix)
            const groups = {};
            for (const file of imageFiles) {
              const match = file.match(/^(.+?)_(baseline|current|diff)\.png$/);
              if (match) {
                const testName = match[1];
                const type = match[2];
                if (!groups[testName]) groups[testName] = {};
                groups[testName][type] = file;
              }
            }

            for (const [testName, images] of Object.entries(groups)) {
              body += `#### ${testName}\n\n`;

              // Show Current always, Baseline and Diff only if present (failure case)
              if (images.baseline || images.diff) {
                body += `| Baseline | Current | Diff |\n`;
                body += `|----------|---------|------|\n`;
                const baseline = images.baseline
                  ? `![baseline](${rawBase}/${images.baseline})`
                  : 'N/A';
                const current = images.current
                  ? `![current](${rawBase}/${images.current})`
                  : 'N/A';
                const diff = images.diff
                  ? `![diff](${rawBase}/${images.diff})`
                  : 'N/A';
                body += `| ${baseline} | ${current} | ${diff} |\n\n`;
              } else if (images.current) {
                body += `**Current:**\n\n`;
                body += `![${testName}](${rawBase}/${images.current})\n\n`;
              }
            }
          } else {
            body += `No visual test images were generated.\n\n`;
          }

          body += `---\n`;
          body += `*Generated by [Visual Regression Tests](${runUrl})*`;

          // Find existing comment to update (don't spam)
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });

          const botComment = comments.find(comment =>
            comment.user.type === 'Bot' &&
            comment.body.includes('Visual Regression Test Report')
          );

          if (botComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComment.id,
              body: body
            });
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });
          }
